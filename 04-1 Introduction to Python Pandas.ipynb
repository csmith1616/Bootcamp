{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 - Installing and Importing Modules (Pandas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Write a command to install the pandas library in your environment.\n",
    "\n",
    "Note: It’s important to install pandas because it provides data structures and data analysis tools for the Python programming language.\n",
    "\n",
    "Python raw would not need the % or !\n",
    "Depending on the verison of Jupyter Notebook a % or ! will be needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandasNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script f2py.exe is installed in 'c:\\Users\\coxc1\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading pandas-2.2.1-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting numpy<2,>=1.26.0 (from pandas)\n",
      "  Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "     ---------------------------------------- 0.0/61.0 kB ? eta -:--:--\n",
      "     ------------ ------------------------- 20.5/61.0 kB 330.3 kB/s eta 0:00:01\n",
      "     -------------------------------------- 61.0/61.0 kB 819.4 kB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\coxc1\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\coxc1\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.1-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "   ---------------------------------------- 0.0/11.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/11.5 MB 4.1 MB/s eta 0:00:03\n",
      "    --------------------------------------- 0.2/11.5 MB 2.5 MB/s eta 0:00:05\n",
      "    --------------------------------------- 0.2/11.5 MB 1.6 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.3/11.5 MB 2.2 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.4/11.5 MB 2.1 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.5/11.5 MB 2.1 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 0.6/11.5 MB 2.0 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 0.7/11.5 MB 1.9 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 0.7/11.5 MB 1.9 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 0.8/11.5 MB 1.9 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 1.0/11.5 MB 1.9 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 1.0/11.5 MB 2.0 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 1.1/11.5 MB 1.9 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.2/11.5 MB 1.9 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.3/11.5 MB 1.9 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 1.4/11.5 MB 2.0 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 1.5/11.5 MB 2.0 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 1.6/11.5 MB 2.0 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 1.7/11.5 MB 2.0 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 1.8/11.5 MB 2.0 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 1.9/11.5 MB 2.0 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 2.0/11.5 MB 2.0 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 2.1/11.5 MB 2.0 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 2.2/11.5 MB 2.0 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 2.3/11.5 MB 2.0 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 2.4/11.5 MB 2.1 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 2.5/11.5 MB 2.0 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 2.6/11.5 MB 2.0 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 2.7/11.5 MB 2.0 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 2.8/11.5 MB 2.0 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 2.9/11.5 MB 2.1 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 3.0/11.5 MB 2.1 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 3.1/11.5 MB 2.1 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 3.2/11.5 MB 2.1 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 3.3/11.5 MB 2.1 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 3.5/11.5 MB 2.1 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 3.6/11.5 MB 2.1 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 3.6/11.5 MB 2.1 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 3.7/11.5 MB 2.1 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 3.8/11.5 MB 2.1 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 3.9/11.5 MB 2.1 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 4.0/11.5 MB 2.1 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 4.1/11.5 MB 2.1 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 4.2/11.5 MB 2.1 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 4.3/11.5 MB 2.1 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 4.5/11.5 MB 2.1 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 4.6/11.5 MB 2.1 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 4.7/11.5 MB 2.1 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 4.8/11.5 MB 2.1 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 4.9/11.5 MB 2.1 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 4.9/11.5 MB 2.1 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 5.0/11.5 MB 2.1 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 5.1/11.5 MB 2.1 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 5.2/11.5 MB 2.1 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 5.3/11.5 MB 2.1 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 5.3/11.5 MB 2.1 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 5.4/11.5 MB 2.1 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 5.5/11.5 MB 2.1 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 5.6/11.5 MB 2.1 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 5.6/11.5 MB 2.0 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 5.7/11.5 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 5.8/11.5 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 5.9/11.5 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 6.0/11.5 MB 2.0 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 6.1/11.5 MB 2.0 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 6.1/11.5 MB 2.0 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 6.2/11.5 MB 2.0 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 6.3/11.5 MB 2.0 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 6.4/11.5 MB 2.0 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 6.5/11.5 MB 2.0 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 6.5/11.5 MB 2.0 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 6.6/11.5 MB 2.0 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 6.7/11.5 MB 2.0 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 6.8/11.5 MB 2.0 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 6.9/11.5 MB 2.0 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 7.0/11.5 MB 2.0 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 7.1/11.5 MB 2.0 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 7.2/11.5 MB 2.0 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 7.3/11.5 MB 2.0 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 7.4/11.5 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 7.5/11.5 MB 2.0 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 7.6/11.5 MB 2.0 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 7.6/11.5 MB 2.0 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 7.7/11.5 MB 2.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 7.8/11.5 MB 2.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 7.9/11.5 MB 2.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.0/11.5 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 8.1/11.5 MB 2.0 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 8.2/11.5 MB 2.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 8.3/11.5 MB 2.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 8.4/11.5 MB 2.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 8.5/11.5 MB 2.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 8.6/11.5 MB 2.0 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 8.7/11.5 MB 2.0 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 8.8/11.5 MB 2.0 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 8.9/11.5 MB 2.0 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 9.0/11.5 MB 2.0 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 9.1/11.5 MB 2.0 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 9.2/11.5 MB 2.0 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 9.3/11.5 MB 2.0 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 9.4/11.5 MB 2.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.5/11.5 MB 2.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.7/11.5 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.8/11.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.9/11.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.0/11.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.0/11.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.2/11.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.2/11.5 MB 2.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.3/11.5 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.4/11.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.5/11.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.6/11.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.7/11.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.8/11.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.9/11.5 MB 2.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.0/11.5 MB 2.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.1/11.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.2/11.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.3/11.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.4/11.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.5/11.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.5/11.5 MB 2.1 MB/s eta 0:00:00\n",
      "Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "   ---------------------------------------- 0.0/15.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/15.5 MB 2.6 MB/s eta 0:00:06\n",
      "   ---------------------------------------- 0.2/15.5 MB 2.1 MB/s eta 0:00:08\n",
      "    --------------------------------------- 0.3/15.5 MB 2.2 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.4/15.5 MB 2.3 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.5/15.5 MB 2.3 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.6/15.5 MB 2.3 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.7/15.5 MB 2.3 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.8/15.5 MB 2.1 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.8/15.5 MB 2.2 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.9/15.5 MB 2.1 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 1.0/15.5 MB 2.0 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 1.1/15.5 MB 2.0 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 1.2/15.5 MB 2.0 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 1.3/15.5 MB 2.0 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 1.3/15.5 MB 2.0 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 1.4/15.5 MB 1.9 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 1.5/15.5 MB 2.0 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 1.6/15.5 MB 2.0 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 1.7/15.5 MB 1.9 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 1.8/15.5 MB 1.9 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 1.9/15.5 MB 1.9 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 1.9/15.5 MB 2.0 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 1.9/15.5 MB 2.0 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 2.0/15.5 MB 1.8 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 2.1/15.5 MB 1.8 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 2.2/15.5 MB 1.8 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 2.2/15.5 MB 1.8 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 2.3/15.5 MB 1.8 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 2.4/15.5 MB 1.8 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 2.5/15.5 MB 1.8 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 2.5/15.5 MB 1.8 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 2.7/15.5 MB 1.8 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 2.7/15.5 MB 1.8 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 2.8/15.5 MB 1.8 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 2.8/15.5 MB 1.8 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 2.9/15.5 MB 1.7 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 3.0/15.5 MB 1.7 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 3.1/15.5 MB 1.8 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 3.2/15.5 MB 1.8 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 3.2/15.5 MB 1.8 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 3.3/15.5 MB 1.8 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 3.4/15.5 MB 1.8 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 3.5/15.5 MB 1.8 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 3.6/15.5 MB 1.8 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 3.6/15.5 MB 1.8 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 3.7/15.5 MB 1.8 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 3.8/15.5 MB 1.8 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 3.9/15.5 MB 1.8 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 4.0/15.5 MB 1.8 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 4.1/15.5 MB 1.8 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 4.1/15.5 MB 1.8 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 4.3/15.5 MB 1.8 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 4.3/15.5 MB 1.8 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 4.4/15.5 MB 1.8 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 4.5/15.5 MB 1.8 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 4.6/15.5 MB 1.8 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 4.7/15.5 MB 1.8 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 4.8/15.5 MB 1.8 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 4.9/15.5 MB 1.8 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 5.0/15.5 MB 1.8 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 5.0/15.5 MB 1.8 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 5.1/15.5 MB 1.8 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 5.2/15.5 MB 1.8 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 5.3/15.5 MB 1.8 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 5.4/15.5 MB 1.8 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 5.5/15.5 MB 1.8 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 5.6/15.5 MB 1.8 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 5.7/15.5 MB 1.8 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 5.8/15.5 MB 1.8 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 5.9/15.5 MB 1.8 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 5.9/15.5 MB 1.8 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 6.1/15.5 MB 1.8 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 6.2/15.5 MB 1.8 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 6.2/15.5 MB 1.8 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 6.3/15.5 MB 1.8 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 6.5/15.5 MB 1.8 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 6.5/15.5 MB 1.8 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 6.6/15.5 MB 1.8 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 6.7/15.5 MB 1.9 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 6.8/15.5 MB 1.9 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 7.0/15.5 MB 1.9 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 7.1/15.5 MB 1.9 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 7.2/15.5 MB 1.9 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 7.3/15.5 MB 1.9 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 7.4/15.5 MB 1.9 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 7.5/15.5 MB 1.9 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 7.6/15.5 MB 1.9 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 7.7/15.5 MB 1.9 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 7.9/15.5 MB 1.9 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 8.0/15.5 MB 1.9 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 8.0/15.5 MB 1.9 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 8.2/15.5 MB 1.9 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 8.2/15.5 MB 1.9 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 8.3/15.5 MB 1.9 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 8.5/15.5 MB 1.9 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 8.6/15.5 MB 1.9 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 8.7/15.5 MB 1.9 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 8.8/15.5 MB 1.9 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 8.9/15.5 MB 1.9 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 8.9/15.5 MB 1.9 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 9.0/15.5 MB 1.9 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 9.1/15.5 MB 1.9 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 9.2/15.5 MB 1.9 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 9.3/15.5 MB 1.9 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 9.4/15.5 MB 1.9 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 9.5/15.5 MB 1.9 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 9.6/15.5 MB 1.9 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 9.7/15.5 MB 1.9 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 9.8/15.5 MB 1.9 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 9.9/15.5 MB 1.9 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 10.0/15.5 MB 1.9 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 10.1/15.5 MB 1.9 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 10.2/15.5 MB 2.0 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 10.4/15.5 MB 2.0 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 10.5/15.5 MB 2.0 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 10.6/15.5 MB 2.0 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 10.7/15.5 MB 2.0 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 10.8/15.5 MB 2.0 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 10.9/15.5 MB 2.0 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 11.1/15.5 MB 2.0 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 11.2/15.5 MB 2.0 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 11.3/15.5 MB 2.0 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 11.4/15.5 MB 2.0 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 11.5/15.5 MB 2.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 11.6/15.5 MB 2.0 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 11.7/15.5 MB 2.0 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 11.9/15.5 MB 2.0 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 12.0/15.5 MB 2.0 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 12.1/15.5 MB 2.0 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 12.2/15.5 MB 2.1 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 12.3/15.5 MB 2.1 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 12.4/15.5 MB 2.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 12.5/15.5 MB 2.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 12.6/15.5 MB 2.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 12.7/15.5 MB 2.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 12.9/15.5 MB 2.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 12.9/15.5 MB 2.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 13.1/15.5 MB 2.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 13.2/15.5 MB 2.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 13.3/15.5 MB 2.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 13.4/15.5 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.5/15.5 MB 2.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 13.6/15.5 MB 2.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 13.7/15.5 MB 2.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 13.8/15.5 MB 2.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 13.8/15.5 MB 2.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 13.9/15.5 MB 2.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 14.0/15.5 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 14.1/15.5 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 14.2/15.5 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 14.3/15.5 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 14.3/15.5 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.5/15.5 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.6/15.5 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.6/15.5 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.7/15.5 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.7/15.5 MB 2.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.8/15.5 MB 2.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.8/15.5 MB 2.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.9/15.5 MB 2.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 15.1/15.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.2/15.5 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.3/15.5 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.4/15.5 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.5/15.5 MB 2.1 MB/s eta 0:00:00\n",
      "Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "   ---------------------------------------- 0.0/505.5 kB ? eta -:--:--\n",
      "   -- ------------------------------------ 30.7/505.5 kB 660.6 kB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 204.8/505.5 kB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 327.7/505.5 kB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 440.3/505.5 kB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 505.5/505.5 kB 2.3 MB/s eta 0:00:00\n",
      "Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "   ---------------------------------------- 0.0/345.4 kB ? eta -:--:--\n",
      "   ------------- -------------------------- 112.6/345.4 kB 3.3 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 225.3/345.4 kB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  337.9/345.4 kB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 345.4/345.4 kB 2.4 MB/s eta 0:00:00\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "Successfully installed numpy-1.26.4 pandas-2.2.1 pytz-2024.1 tzdata-2024.1\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Write a command to install a specific version (2.1.1) of pandas.\n",
    "\n",
    "Note: Sometimes, you might need to work with a specific version of pandas due to compatibility issues with other libraries or specific features available in that version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Write a command to import the pandas library as ‘pd’.\n",
    "\n",
    "Note: It’s a common convention to import pandas as pd. This makes your code shorter and more readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Write a command to create a pandas Series named ‘fruits’ with the values [‘apple’, ‘banana’, ‘cherry’].\n",
    "\n",
    "Note: A Series is a one-dimensional labeled array capable of holding any data type. It is one of the basic structures in pandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = ['apple','banana','cherry']\n",
    "series = pd.Series(data, name=\"MySeries\")\n",
    "\n",
    "series = series * 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Create a DataFrame named ‘purchases’ with two columns ‘apples’ and ‘oranges’.\n",
    "\n",
    "```\n",
    "The ‘apples’ column should have the values [3, 2, 0, 1] and the ‘oranges’ column should have the values [0, 3, 7, 2].\n",
    "```\n",
    "\n",
    "Note: DataFrames are two-dimensional size-mutable, potentially heterogeneous tabular data structures with labeled axes (rows and columns). They are one of the fundamental structures in pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   apples  oranges\n",
      "0       3        0\n",
      "1       2        3\n",
      "2       0        7\n",
      "3       1        2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = ({\n",
    "    'apples': [3,2,0,1],\n",
    "    'oranges': [0,3,7,2]\n",
    "})\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 - Data Loading in Pandas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Write a line of code to open the ‘employees.csv’ data file into a pandas DataFrame.\n",
    "\n",
    "```\n",
    "The employees.csv file will need to be in the same directory(folder) as the notebook, or the filepath will need to be added.\n",
    "```\n",
    "\n",
    "Note: This function is useful for loading CSV data into a pandas DataFrame, which is a two-dimensional labeled data structure with columns of potentially different types. It’s one of the most common initial steps in data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('employees.csv')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Write a line of code to display the first 5 rows of the DataFrame.\n",
    "\n",
    "Note: The .head(n) function is useful for quickly previewing the first n rows of your DataFrame, which can help you get a sense of your data at a glance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Name   Age            City    Salary    Gender      column1  \\\n",
      "0        kyle   59.0   indianapolis   151000.0    Other      Raymond    \n",
      "1        Luis   31.0    Los Angeles    58000.0       NaN     Andrade    \n",
      "2   katherine   46.0     Naperville   146000.0   female    Gutierrez    \n",
      "3      robert   25.0     pittsburgh    66000.0     Male        Yates    \n",
      "4      austin   49.0     Naperville    96000.0       NaN      Turner    \n",
      "\n",
      "            State    Start Date                 DateOfBirth  \n",
      "0        Indiana     1990-12-09  1964-10-15 14:21:44.568274  \n",
      "1             CA     1992-02-24  1992-10-08 14:21:44.568274  \n",
      "2             IL    21-12-2015   1977-10-12 14:21:44.568274  \n",
      "3   Pennsylvania     1993-01-25  1998-10-07 14:21:44.568274  \n",
      "4             IL    20-09-1979   1974-10-13 14:21:44.568274  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('employees.csv')\n",
    "print(df.head(5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Write a line of code to display the last 3 rows of the DataFrame.\n",
    "\n",
    "Note: The .tail(n) function is useful for quickly viewing the last n rows of your DataFrame. This can be particularly helpful when you want to see the most recent entries in a time-series dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Name   Age             City   Salary  Gender      column1  \\\n",
      "157      Laura   28.0      Pittsburgh   53000.0   male      Jackson    \n",
      "158      kiara   54.0           Tampa   33000.0     NaN   Hernandez    \n",
      "159   Jennifer   38.0   san francisco   58000.0     NaN      Palmer    \n",
      "\n",
      "              State    Start Date                 DateOfBirth  \n",
      "157   Pennsylvania     1991-05-05  1995-10-08 14:21:44.568274  \n",
      "158        Florida    03-01-1985   1969-10-14 14:21:44.568274  \n",
      "159             CA     2017-01-31  1985-10-10 14:21:44.568274  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('employees.csv')\n",
    "print(df.tail(3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Write a line of code to randomly select 7 rows from the DataFrame.\n",
    "\n",
    "Note: The .sample(n) function is useful when you want to randomly select n rows from your DataFrame. This can be helpful for creating random samples from your data for tasks like bootstrapping or cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Name   Age            City    Salary    Gender      column1  \\\n",
      "128   cassidy   31.0          Miami    96000.0    Other        Brown    \n",
      "38      kiara   54.0          Tampa    33000.0       NaN   Hernandez    \n",
      "111    dennis   48.0      san diego   159000.0   Female       Conner    \n",
      "31     Amanda   50.0      rochester   114000.0     Male       Oliver    \n",
      "123      Paul   56.0   jacksonville    82000.0   Female         Moon    \n",
      "120     laura   30.0    los angeles   134000.0     Male       Torres    \n",
      "35     Morgan   42.0    Los Angeles    66000.0     Male        Smith    \n",
      "\n",
      "         State    Start Date                 DateOfBirth  \n",
      "128   Florida     1993-11-09  1992-10-08 14:21:44.568274  \n",
      "38    Florida    03-01-1985   1969-10-14 14:21:44.568274  \n",
      "111        CA     1986-11-04  1975-10-13 14:21:44.568274  \n",
      "31         NY     2017-10-19  1973-10-13 14:21:44.568274  \n",
      "123   Florida     1992-02-24  1967-10-15 14:21:44.568274  \n",
      "120        CA     1988-07-08  1993-10-08 14:21:44.568274  \n",
      "35         CA     1993-11-09  1981-10-11 14:21:44.568274  \n"
     ]
    }
   ],
   "source": [
    "print(df.sample(7))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Write a line of code to save the DataFrame back to a new CSV file named ‘new_employees.csv’.\n",
    "\n",
    "```\n",
    "df.to_csv('new_employees.csv', index=False)\n",
    "```\n",
    "\n",
    "index=False tells the function not to write the row index to file.\n",
    "\n",
    "Note: The .to_csv() function is useful for saving your DataFrame back to a CSV file. This is often used after you’ve made some modifications to your data and want to save the results for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('new_employees.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Write a line of code to open a CSV file named ‘separator.csv’ that uses a semicolon (;) as the separator.\n",
    "\n",
    "Note: In CSV files, a separator (also known as a delimiter) is used to distinguish between different fields.\n",
    "\n",
    "The most common separator is a comma, but other characters can be used as well, such as semicolons, tabs (\\t), spaces, etc.\n",
    "\n",
    "The choice of separator can depend on the data itself (for example, if the data contains commas within fields, a different separator might be used).\n",
    "\n",
    "When reading a CSV file with pandas, you can specify the separator using the sep parameter in the read_csv function.\n",
    "\n",
    "If not specified, pandas will assume the separator is a comma.\n",
    "\n",
    "It’s important to know what separator is used in your data file to correctly load it into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('separator.csv', delimiter=';')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. Write a line of code to get the shape of the DataFrame.\n",
    "\n",
    "Note: The .shape attribute is useful for quickly finding out how many rows and columns are in your DataFrame. It returns a tuple in the format (rows, columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Name   Age             City    Salary    Gender      column1  \\\n",
      "0          kyle   59.0    indianapolis   151000.0    Other      Raymond    \n",
      "1          Luis   31.0     Los Angeles    58000.0       NaN     Andrade    \n",
      "2     katherine   46.0      Naperville   146000.0   female    Gutierrez    \n",
      "3        robert   25.0      pittsburgh    66000.0     Male        Yates    \n",
      "4        austin   49.0      Naperville    96000.0       NaN      Turner    \n",
      "..           ...   ...              ...       ...       ...          ...   \n",
      "155    Jennifer   38.0   san francisco    58000.0       NaN      Palmer    \n",
      "156        Sean   35.0     Los Angeles    70000.0     Male       Harris    \n",
      "157       Laura   28.0      Pittsburgh    53000.0     male      Jackson    \n",
      "158       kiara   54.0           Tampa    33000.0       NaN   Hernandez    \n",
      "159    Jennifer   38.0   san francisco    58000.0       NaN      Palmer    \n",
      "\n",
      "              State    Start Date DateOfBirth  \n",
      "0          Indiana     1990-12-09  1964-10-15  \n",
      "1               CA     1992-02-24  1992-10-08  \n",
      "2               IL    21-12-2015   1977-10-12  \n",
      "3     Pennsylvania     1993-01-25  1998-10-07  \n",
      "4               IL    20-09-1979   1974-10-13  \n",
      "..              ...           ...         ...  \n",
      "155             CA     2017-01-31  1985-10-10  \n",
      "156             CA     2011-07-06  1988-10-09  \n",
      "157   Pennsylvania     1991-05-05  1995-10-08  \n",
      "158        Florida    03-01-1985   1969-10-14  \n",
      "159             CA     2017-01-31  1985-10-10  \n",
      "\n",
      "[160 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "df.shape\n",
    "print(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. Write a line of code to get a summary of the DataFrame’s numerical columns.\n",
    "\n",
    "Note: The .describe() function is useful for quickly generating descriptive statistics that summarize the central tendency, dispersion, and shape of a dataset’s distribution. It automatically excludes NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Age         Salary\n",
      "count  159.000000     159.000000\n",
      "mean    40.773585   86503.144654\n",
      "std     11.125250   40741.835280\n",
      "min     20.000000   23000.000000\n",
      "25%     32.000000   54000.000000\n",
      "50%     41.000000   77000.000000\n",
      "75%     50.000000  115000.000000\n",
      "max     59.000000  191000.000000\n"
     ]
    }
   ],
   "source": [
    "df.describe\n",
    "print(df.describe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9. Write a line of code to get a concise summary of the DataFrame.\n",
    "\n",
    "Note: The .info() function is useful for getting a quick description of the data, especially the total number of non-null observations and the data type of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 160 entries, 0 to 159\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Name         160 non-null    object \n",
      " 1   Age          159 non-null    float64\n",
      " 2   City         156 non-null    object \n",
      " 3   Salary       159 non-null    float64\n",
      " 4   Gender       118 non-null    object \n",
      " 5   column1      158 non-null    object \n",
      " 6   State        156 non-null    object \n",
      " 7   Start Date   158 non-null    object \n",
      " 8   DateOfBirth  152 non-null    object \n",
      "dtypes: float64(2), object(7)\n",
      "memory usage: 11.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10. Write a line of code to get the number of unique values in each column.\n",
    "\n",
    "Note: The .nunique() function is useful for understanding the number of distinct values in each column. This can help identify columns with high cardinality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name           129\n",
       "Age             40\n",
       "City            46\n",
       "Salary          91\n",
       "Gender           7\n",
       "column1        126\n",
       "State            9\n",
       "Start Date      30\n",
       "DateOfBirth     50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 11. Write a line of code to select all data from the ‘Age’ column.\n",
    "\n",
    "Note: Selecting a single column from your DataFrame is useful when you want to analyze or manipulate that specific column of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      59.0\n",
       "1      31.0\n",
       "2      46.0\n",
       "3      25.0\n",
       "4      49.0\n",
       "       ... \n",
       "155    38.0\n",
       "156    35.0\n",
       "157    28.0\n",
       "158    54.0\n",
       "159    38.0\n",
       "Name: Age, Length: 160, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Age']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 12.  Write a line of code to calculate the mean age.\n",
    "\n",
    "Note: The .mode() function is used to find the most frequently occurring value(s) in a series. This can be useful when analyzing categorical data or certain types of numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    54.0\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Age.mode()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 13. Write a line of code to find the median salary.\n",
    "\n",
    "Note: The .median() function is used to find the middle value in a series when it’s sorted in ascending order. This can be more informative than the mean for datasets with skewed distributions or outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Age.median()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Data Cleaning in Pandas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Write a line of code to drop the ‘column1’ from the DataFrame.\n",
    "\n",
    "Note: The .drop() function is useful for removing rows or columns by label names and corresponding axis, or by specifying directly index or column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Gender</th>\n",
       "      <th>State</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>DateOfBirth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kyle</td>\n",
       "      <td>59.0</td>\n",
       "      <td>indianapolis</td>\n",
       "      <td>151000.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>1990-12-09</td>\n",
       "      <td>1964-10-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Luis</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA</td>\n",
       "      <td>1992-02-24</td>\n",
       "      <td>1992-10-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>katherine</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Naperville</td>\n",
       "      <td>146000.0</td>\n",
       "      <td>female</td>\n",
       "      <td>IL</td>\n",
       "      <td>21-12-2015</td>\n",
       "      <td>1977-10-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>robert</td>\n",
       "      <td>25.0</td>\n",
       "      <td>pittsburgh</td>\n",
       "      <td>66000.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>1993-01-25</td>\n",
       "      <td>1998-10-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>austin</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Naperville</td>\n",
       "      <td>96000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IL</td>\n",
       "      <td>20-09-1979</td>\n",
       "      <td>1974-10-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Jennifer</td>\n",
       "      <td>38.0</td>\n",
       "      <td>san francisco</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA</td>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>1985-10-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Sean</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>CA</td>\n",
       "      <td>2011-07-06</td>\n",
       "      <td>1988-10-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Laura</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>53000.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>1991-05-05</td>\n",
       "      <td>1995-10-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>kiara</td>\n",
       "      <td>54.0</td>\n",
       "      <td>Tampa</td>\n",
       "      <td>33000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Florida</td>\n",
       "      <td>03-01-1985</td>\n",
       "      <td>1969-10-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Jennifer</td>\n",
       "      <td>38.0</td>\n",
       "      <td>san francisco</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA</td>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>1985-10-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name   Age             City    Salary    Gender           State  \\\n",
       "0          kyle   59.0    indianapolis   151000.0    Other         Indiana    \n",
       "1          Luis   31.0     Los Angeles    58000.0       NaN             CA    \n",
       "2     katherine   46.0      Naperville   146000.0   female              IL    \n",
       "3        robert   25.0      pittsburgh    66000.0     Male    Pennsylvania    \n",
       "4        austin   49.0      Naperville    96000.0       NaN             IL    \n",
       "..           ...   ...              ...       ...       ...             ...   \n",
       "155    Jennifer   38.0   san francisco    58000.0       NaN             CA    \n",
       "156        Sean   35.0     Los Angeles    70000.0     Male              CA    \n",
       "157       Laura   28.0      Pittsburgh    53000.0     male    Pennsylvania    \n",
       "158       kiara   54.0           Tampa    33000.0       NaN        Florida    \n",
       "159    Jennifer   38.0   san francisco    58000.0       NaN             CA    \n",
       "\n",
       "       Start Date DateOfBirth  \n",
       "0      1990-12-09  1964-10-15  \n",
       "1      1992-02-24  1992-10-08  \n",
       "2     21-12-2015   1977-10-12  \n",
       "3      1993-01-25  1998-10-07  \n",
       "4     20-09-1979   1974-10-13  \n",
       "..            ...         ...  \n",
       "155    2017-01-31  1985-10-10  \n",
       "156    2011-07-06  1988-10-09  \n",
       "157    1991-05-05  1995-10-08  \n",
       "158   03-01-1985   1969-10-14  \n",
       "159    2017-01-31  1985-10-10  \n",
       "\n",
       "[160 rows x 8 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe\n",
    "df.drop(columns='column1')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Write a line of code to fill missing values in the ‘Age’ column with the average age.\n",
    "\n",
    "```\n",
    "This demonstrates the function of the mean function and utlises imputation, but does it make sense to create an Employees age from a Mean? In this situation it would be better to request a real age for an employee from the data source, or remove that emplyee if it is histroical data.\n",
    "```\n",
    "\n",
    "Note: The .fillna() function is used to fill NA/NaN values using the specified method which can be a constant or a DataFrame method like mean, median etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      59.0\n",
       "1      31.0\n",
       "2      46.0\n",
       "3      25.0\n",
       "4      49.0\n",
       "       ... \n",
       "155    38.0\n",
       "156    35.0\n",
       "157    28.0\n",
       "158    54.0\n",
       "159    38.0\n",
       "Name: Age, Length: 160, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Age'].fillna(value=df['Age'].mean)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Write a line of code to drop rows with any missing values.\n",
    "\n",
    "Note: The .dropna() function is used to remove missing values. It’s useful when you want to discard any incomplete data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Gender</th>\n",
       "      <th>column1</th>\n",
       "      <th>State</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>DateOfBirth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kyle</td>\n",
       "      <td>59.0</td>\n",
       "      <td>indianapolis</td>\n",
       "      <td>151000.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>Raymond</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>1990-12-09</td>\n",
       "      <td>1964-10-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>katherine</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Naperville</td>\n",
       "      <td>146000.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Gutierrez</td>\n",
       "      <td>IL</td>\n",
       "      <td>21-12-2015</td>\n",
       "      <td>1977-10-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>robert</td>\n",
       "      <td>25.0</td>\n",
       "      <td>pittsburgh</td>\n",
       "      <td>66000.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yates</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>1993-01-25</td>\n",
       "      <td>1998-10-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>christopher</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Buffalo</td>\n",
       "      <td>47000.0</td>\n",
       "      <td>other</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>NY</td>\n",
       "      <td>1990-12-09</td>\n",
       "      <td>1975-10-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>michelle</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Fort Wayne</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Anderson</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>1991-05-05</td>\n",
       "      <td>1978-10-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>brooke</td>\n",
       "      <td>46.0</td>\n",
       "      <td>dallas</td>\n",
       "      <td>51000.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Wilson</td>\n",
       "      <td>TX</td>\n",
       "      <td>1999-05-26</td>\n",
       "      <td>1977-10-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Felicia</td>\n",
       "      <td>47.0</td>\n",
       "      <td>san antonio</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Willis</td>\n",
       "      <td>TX</td>\n",
       "      <td>2013-04-23</td>\n",
       "      <td>1976-10-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Kevin</td>\n",
       "      <td>39.0</td>\n",
       "      <td>tucson</td>\n",
       "      <td>91000.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Graham</td>\n",
       "      <td>AZ</td>\n",
       "      <td>2006-07-11</td>\n",
       "      <td>1984-10-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Sean</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Harris</td>\n",
       "      <td>CA</td>\n",
       "      <td>2011-07-06</td>\n",
       "      <td>1988-10-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Laura</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>53000.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Jackson</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>1991-05-05</td>\n",
       "      <td>1995-10-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name   Age            City    Salary    Gender      column1  \\\n",
       "0            kyle   59.0   indianapolis   151000.0    Other      Raymond    \n",
       "2       katherine   46.0     Naperville   146000.0   female    Gutierrez    \n",
       "3          robert   25.0     pittsburgh    66000.0     Male        Yates    \n",
       "5     christopher   48.0        Buffalo    47000.0    other      Carroll    \n",
       "6        michelle   45.0     Fort Wayne    61000.0     Male     Anderson    \n",
       "..             ...   ...             ...       ...       ...          ...   \n",
       "151        brooke   46.0         dallas    51000.0     Male       Wilson    \n",
       "153       Felicia   47.0    san antonio   110000.0   Female       Willis    \n",
       "154         Kevin   39.0         tucson    91000.0     male       Graham    \n",
       "156          Sean   35.0    Los Angeles    70000.0     Male       Harris    \n",
       "157         Laura   28.0     Pittsburgh    53000.0     male      Jackson    \n",
       "\n",
       "              State    Start Date DateOfBirth  \n",
       "0          Indiana     1990-12-09  1964-10-15  \n",
       "2               IL    21-12-2015   1977-10-12  \n",
       "3     Pennsylvania     1993-01-25  1998-10-07  \n",
       "5               NY     1990-12-09  1975-10-13  \n",
       "6          Indiana     1991-05-05  1978-10-12  \n",
       "..              ...           ...         ...  \n",
       "151             TX     1999-05-26  1977-10-12  \n",
       "153             TX     2013-04-23  1976-10-12  \n",
       "154             AZ     2006-07-11  1984-10-10  \n",
       "156             CA     2011-07-06  1988-10-09  \n",
       "157   Pennsylvania     1991-05-05  1995-10-08  \n",
       "\n",
       "[109 rows x 9 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Write a line of code to find duplicated rows.\n",
    "\n",
    "Note: The .duplicated() function returns a Boolean Series denoting duplicate rows. It’s useful when you want to identify any repeated data in your DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Name   Age             City    Salary    Gender      column1  \\\n",
      "150    patrick   39.0       allentown    89000.0       NaN      Walker    \n",
      "151     brooke   46.0          dallas    51000.0     Male       Wilson    \n",
      "152     angela   40.0          Aurora    75000.0       NaN      Rhodes    \n",
      "153    Felicia   47.0     san antonio   110000.0   Female       Willis    \n",
      "154      Kevin   39.0          tucson    91000.0     male       Graham    \n",
      "155   Jennifer   38.0   san francisco    58000.0       NaN      Palmer    \n",
      "156       Sean   35.0     Los Angeles    70000.0     Male       Harris    \n",
      "157      Laura   28.0      Pittsburgh    53000.0     male      Jackson    \n",
      "158      kiara   54.0           Tampa    33000.0       NaN   Hernandez    \n",
      "159   Jennifer   38.0   san francisco    58000.0       NaN      Palmer    \n",
      "\n",
      "              State    Start Date                 DateOfBirth  \n",
      "150   Pennsylvania     1992-02-24  1984-10-10 14:21:44.568274  \n",
      "151             TX     1999-05-26  1977-10-12 14:21:44.568274  \n",
      "152             IL     1988-07-08  1983-10-11 14:21:44.568274  \n",
      "153             TX     2013-04-23  1976-10-12 14:21:44.568274  \n",
      "154             AZ     2006-07-11  1984-10-10 14:21:44.568274  \n",
      "155             CA     2017-01-31  1985-10-10 14:21:44.568274  \n",
      "156             CA     2011-07-06  1988-10-09 14:21:44.568274  \n",
      "157   Pennsylvania     1991-05-05  1995-10-08 14:21:44.568274  \n",
      "158        Florida    03-01-1985   1969-10-14 14:21:44.568274  \n",
      "159             CA     2017-01-31  1985-10-10 14:21:44.568274  \n"
     ]
    }
   ],
   "source": [
    "duplicates = df[df.duplicated(subset=['Name', 'Age'])]\n",
    "print(duplicates)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Write a line of code to drop duplicated rows.\n",
    "\n",
    "Note: The .drop_duplicates() function is used to remove duplicate rows. This is often necessary in data cleaning process to get rid of repeated information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(152, 9)\n",
      "             Name   Age            City    Salary    Gender      column1  \\\n",
      "0           kyle   59.0   indianapolis   151000.0    Other      Raymond    \n",
      "1           Luis   31.0    Los Angeles    58000.0       NaN     Andrade    \n",
      "2      katherine   46.0     Naperville   146000.0   female    Gutierrez    \n",
      "3         robert   25.0     pittsburgh    66000.0     Male        Yates    \n",
      "4         austin   49.0     Naperville    96000.0       NaN      Turner    \n",
      "..            ...   ...             ...       ...       ...          ...   \n",
      "147   Jacqueline   22.0      allentown   150000.0     Male         Hill    \n",
      "148        Paula   50.0             NaN   36000.0     Male      Kennedy    \n",
      "149        Tammy   54.0        Phoenix    29000.0   Female       Pierce    \n",
      "154        Kevin   39.0         tucson    91000.0     male       Graham    \n",
      "156         Sean   35.0    Los Angeles    70000.0     Male       Harris    \n",
      "\n",
      "              State    Start Date DateOfBirth  \n",
      "0          Indiana     1990-12-09  1964-10-15  \n",
      "1               CA     1992-02-24  1992-10-08  \n",
      "2               IL    21-12-2015   1977-10-12  \n",
      "3     Pennsylvania     1993-01-25  1998-10-07  \n",
      "4               IL    20-09-1979   1974-10-13  \n",
      "..              ...           ...         ...  \n",
      "147   Pennsylvania     1999-05-26  2001-10-06  \n",
      "148             NaN    1993-01-25  1973-10-13  \n",
      "149             AZ     1986-11-04  1969-10-14  \n",
      "154             AZ     2006-07-11  1984-10-10  \n",
      "156             CA     2011-07-06  1988-10-09  \n",
      "\n",
      "[152 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.drop_duplicates().shape)\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Write a line of code to replace ‘Illinois’ with ‘IL’ in the ‘State’ column.\n",
    "\n",
    "Note: The .str.replace() function is used to replace a specified phrase with another specified phrase. It’s useful when you want to standardize the data in your DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Name   Age            City    Salary    Gender      column1  \\\n",
      "0           kyle   59.0   indianapolis   151000.0    Other      Raymond    \n",
      "1           Luis   31.0    Los Angeles    58000.0       NaN     Andrade    \n",
      "2      katherine   46.0     Naperville   146000.0   female    Gutierrez    \n",
      "3         robert   25.0     pittsburgh    66000.0     Male        Yates    \n",
      "4         austin   49.0     Naperville    96000.0       NaN      Turner    \n",
      "..            ...   ...             ...       ...       ...          ...   \n",
      "147   Jacqueline   22.0      allentown   150000.0     Male         Hill    \n",
      "148        Paula   50.0             NaN   36000.0     Male      Kennedy    \n",
      "149        Tammy   54.0        Phoenix    29000.0   Female       Pierce    \n",
      "154        Kevin   39.0         tucson    91000.0     male       Graham    \n",
      "156         Sean   35.0    Los Angeles    70000.0     Male       Harris    \n",
      "\n",
      "              State    Start Date DateOfBirth  \n",
      "0               IN     1990-12-09  1964-10-15  \n",
      "1               CA     1992-02-24  1992-10-08  \n",
      "2               IL    21-12-2015   1977-10-12  \n",
      "3     Pennsylvania     1993-01-25  1998-10-07  \n",
      "4               IL    20-09-1979   1974-10-13  \n",
      "..              ...           ...         ...  \n",
      "147   Pennsylvania     1999-05-26  2001-10-06  \n",
      "148             NaN    1993-01-25  1973-10-13  \n",
      "149             AZ     1986-11-04  1969-10-14  \n",
      "154             AZ     2006-07-11  1984-10-10  \n",
      "156             CA     2011-07-06  1988-10-09  \n",
      "\n",
      "[152 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "df['State'] = df['State'].str.replace('Illinois','IL')\n",
    "print(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. Write a line of code to find all rows where ‘City’ contains ‘naperville’.\n",
    "\n",
    "Note: The .str.contains() function is used to test if pattern or regex is contained within a string of a Series or Index. It’s useful when you want to filter your data based on certain text criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Gender</th>\n",
       "      <th>column1</th>\n",
       "      <th>State</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>DateOfBirth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Nicole</td>\n",
       "      <td>41.0</td>\n",
       "      <td>naperville</td>\n",
       "      <td>78000.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>Roberts</td>\n",
       "      <td>IL</td>\n",
       "      <td>2006-07-11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>tyler</td>\n",
       "      <td>20.0</td>\n",
       "      <td>naperville</td>\n",
       "      <td>113000.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Mcdaniel</td>\n",
       "      <td>IL</td>\n",
       "      <td>1988-04-07</td>\n",
       "      <td>2003-10-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name   Age          City    Salary   Gender     column1 State  \\\n",
       "12   Nicole   41.0   naperville    78000.0   Other     Roberts    IL    \n",
       "65    tyler   20.0   naperville   113000.0    male    Mcdaniel    IL    \n",
       "\n",
       "    Start Date DateOfBirth  \n",
       "12  2006-07-11         NaN  \n",
       "65  1988-04-07  2003-10-06  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#contains_pattern = df['City'].str.contains('Naperville')\n",
    "#filtered_data = df[contains_pattern]\n",
    "#print(filtered_data)\n",
    "#df = pd.read_csv('separator.csv', delimiter=';')\n",
    "#contains_pattern = df['City'].str.contains('naperville', na=false)\n",
    "#filtered_data = df[contains_pattern]\n",
    "#print(filtered_data)\n",
    "naperville_rows = df[df['City'].str.contains('naperville', na=False)]\n",
    "naperville_rows"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. Write a line of code to standardize the ‘City’ and ‘State’ columns in the DataFrame. For ‘City’, replace ‘naperville’ with ‘Naperville’, and for ‘State’, replace ‘Illinois’ with ‘IL’.\n",
    "\n",
    "Note: The .str.replace() function is used to replace a specified phrase with another specified phrase. It’s useful when you want to standardise the data in your DataFrame. In this case, we’re using it to ensure that city and state names follow a consistent format. This is an important step in data cleaning, especially when dealing with text data, as it ensures that the same entity is represented in the same way across the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Name   Age             City    Salary    Gender      column1  \\\n",
      "0          kyle   59.0    indianapolis   151000.0    Other      Raymond    \n",
      "1          Luis   31.0     Los Angeles    58000.0       NaN     Andrade    \n",
      "2     katherine   46.0      Naperville   146000.0   female    Gutierrez    \n",
      "3        robert   25.0      pittsburgh    66000.0     Male        Yates    \n",
      "4        austin   49.0      Naperville    96000.0       NaN      Turner    \n",
      "..           ...   ...              ...       ...       ...          ...   \n",
      "155    Jennifer   38.0   san francisco    58000.0       NaN      Palmer    \n",
      "156        Sean   35.0     Los Angeles    70000.0     Male       Harris    \n",
      "157       Laura   28.0      Pittsburgh    53000.0     male      Jackson    \n",
      "158       kiara   54.0           Tampa    33000.0       NaN   Hernandez    \n",
      "159    Jennifer   38.0   san francisco    58000.0       NaN      Palmer    \n",
      "\n",
      "              State    Start Date DateOfBirth  \n",
      "0          Indiana     1990-12-09  1964-10-15  \n",
      "1               CA     1992-02-24  1992-10-08  \n",
      "2               IL    21-12-2015   1977-10-12  \n",
      "3     Pennsylvania     1993-01-25  1998-10-07  \n",
      "4               IL    20-09-1979   1974-10-13  \n",
      "..              ...           ...         ...  \n",
      "155             CA     2017-01-31  1985-10-10  \n",
      "156             CA     2011-07-06  1988-10-09  \n",
      "157   Pennsylvania     1991-05-05  1995-10-08  \n",
      "158        Florida    03-01-1985   1969-10-14  \n",
      "159             CA     2017-01-31  1985-10-10  \n",
      "\n",
      "[160 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "df['City'].str.replace('naperville','Naperville')\n",
    "df['State'].str.replace('Illinois','IL')\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9. (OPTIONAL) Write a line of code to standardize the ‘City’ and ‘State’ columns in the DataFrame.\n",
    "\n",
    "Advanced Question. Will go into more in next lesson so do not worry if you cannot complete this one now.\n",
    "\n",
    "```\n",
    "Reload employees.csv in and output solution to a DataFrame named 'city_state_corrected_df'\n",
    "\n",
    "Any Unknown city or states should be filled with an 'Unknown' string.\n",
    "\n",
    "Run the first code block to create mapping dictionaries for States and City. You can choose to use these or manually type out each state and city and what they should be\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# City to State mapping\n",
    "city_state = {\n",
    "    'New York': 'New York',\n",
    "    'Buffalo': 'New York',\n",
    "    'Rochester': 'New York',\n",
    "    'Los Angeles': 'California',\n",
    "    'San Francisco': 'California',\n",
    "    'San Diego': 'California',\n",
    "    'Houston': 'Texas',\n",
    "    'San Antonio': 'Texas',\n",
    "    'Dallas': 'Texas',\n",
    "    'Jacksonville': 'Florida',\n",
    "    'Miami': 'Florida',\n",
    "    'Tampa': 'Florida',\n",
    "    'Chicago': 'Illinois',\n",
    "    'Aurora': 'Illinois',\n",
    "    'Naperville': 'Illinois',\n",
    "    'Philadelphia': 'Pennsylvania',\n",
    "    'Pittsburgh': 'Pennsylvania',\n",
    "    'Allentown': 'Pennsylvania',\n",
    "    'Phoenix': 'Arizona',\n",
    "    'Tucson': 'Arizona',\n",
    "    'Mesa': 'Arizona',\n",
    "    'Indianapolis': 'Indiana',\n",
    "    'Fort Wayne': 'Indiana',\n",
    "    'Evansville': 'Indiana'\n",
    "}\n",
    "\n",
    "# Abbreviations for some states\n",
    "state_abbr = {\n",
    "    'New York': 'NY',\n",
    "    'California': 'CA',\n",
    "    'Texas': 'TX',\n",
    "    'Florida': 'FL',\n",
    "    'Illinois': 'IL',\n",
    "    'Pennsylvania': 'PA',\n",
    "    'Arizona': 'AZ',\n",
    "    'Indiana': 'IN'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Gender</th>\n",
       "      <th>column1</th>\n",
       "      <th>State</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>DateOfBirth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kyle</td>\n",
       "      <td>59.0</td>\n",
       "      <td>indianapolis</td>\n",
       "      <td>151000.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>Raymond</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>1990-12-09</td>\n",
       "      <td>1964-10-15 14:21:44.568274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Luis</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Andrade</td>\n",
       "      <td>CA</td>\n",
       "      <td>1992-02-24</td>\n",
       "      <td>1992-10-08 14:21:44.568274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>katherine</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Naperville</td>\n",
       "      <td>146000.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Gutierrez</td>\n",
       "      <td>IL</td>\n",
       "      <td>21-12-2015</td>\n",
       "      <td>1977-10-12 14:21:44.568274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Name   Age            City    Salary    Gender      column1  \\\n",
       "0        kyle   59.0   indianapolis   151000.0    Other      Raymond    \n",
       "1        Luis   31.0    Los Angeles    58000.0       NaN     Andrade    \n",
       "2   katherine   46.0     Naperville   146000.0   female    Gutierrez    \n",
       "\n",
       "       State    Start Date                 DateOfBirth  \n",
       "0   Indiana     1990-12-09  1964-10-15 14:21:44.568274  \n",
       "1        CA     1992-02-24  1992-10-08 14:21:44.568274  \n",
       "2        IL    21-12-2015   1977-10-12 14:21:44.568274  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read_csv the employees.csv into the correctly named DataFrame here\n",
    "import pandas as pd\n",
    "df = pd.read_csv('employees.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#df['City'] = df['City'].str.strip().str.title()\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mState\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCity\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcity_state\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#df['State'] = df\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\coxc1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:4691\u001b[0m, in \u001b[0;36mSeries.map\u001b[1;34m(self, arg, na_action)\u001b[0m\n\u001b[0;32m   4611\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\n\u001b[0;32m   4612\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4613\u001b[0m     arg: Callable \u001b[38;5;241m|\u001b[39m Mapping \u001b[38;5;241m|\u001b[39m Series,\n\u001b[0;32m   4614\u001b[0m     na_action: Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   4615\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[0;32m   4616\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4617\u001b[0m \u001b[38;5;124;03m    Map values of Series according to an input mapping or function.\u001b[39;00m\n\u001b[0;32m   4618\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4689\u001b[0m \u001b[38;5;124;03m    dtype: object\u001b[39;00m\n\u001b[0;32m   4690\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4691\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_values, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[0;32m   4693\u001b[0m         \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmap\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4694\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\coxc1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\coxc1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "#df['City'] = df['City'].str.strip().str.title()\n",
    "df['State']= df['City'].map('city_state')\n",
    "#df['State'] = df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10. (OPTIONAL) Perform Data Cleaning on the Gender Column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Data Manipulation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Write a line of code to apply a function that adds 10 to each value in the ‘Age’ column\n",
    "\n",
    "```\n",
    "A lambda function would make the code more readable here.\n",
    "```\n",
    "\n",
    "Note: The .apply() function is useful for applying a function along an axis of the DataFrame. It can be used with a lambda function, as in this case, to perform operations on each element in a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Name   Age             City    Salary    Gender      column1  \\\n",
      "0          kyle   79.0    indianapolis   151000.0    Other      Raymond    \n",
      "1          Luis   51.0     Los Angeles    58000.0       NaN     Andrade    \n",
      "2     katherine   66.0      Naperville   146000.0   female    Gutierrez    \n",
      "3        robert   45.0      pittsburgh    66000.0     Male        Yates    \n",
      "4        austin   69.0      Naperville    96000.0       NaN      Turner    \n",
      "..           ...   ...              ...       ...       ...          ...   \n",
      "155    Jennifer   58.0   san francisco    58000.0       NaN      Palmer    \n",
      "156        Sean   55.0     Los Angeles    70000.0     Male       Harris    \n",
      "157       Laura   48.0      Pittsburgh    53000.0     male      Jackson    \n",
      "158       kiara   74.0           Tampa    33000.0       NaN   Hernandez    \n",
      "159    Jennifer   58.0   san francisco    58000.0       NaN      Palmer    \n",
      "\n",
      "              State    Start Date DateOfBirth  Age plus 10  \n",
      "0          Indiana     1990-12-09  1964-10-15         69.0  \n",
      "1               CA     1992-02-24  1992-10-08         41.0  \n",
      "2               IL    21-12-2015   1977-10-12         56.0  \n",
      "3     Pennsylvania     1993-01-25  1998-10-07         35.0  \n",
      "4               IL    20-09-1979   1974-10-13         59.0  \n",
      "..              ...           ...         ...          ...  \n",
      "155             CA     2017-01-31  1985-10-10         48.0  \n",
      "156             CA     2011-07-06  1988-10-09         45.0  \n",
      "157   Pennsylvania     1991-05-05  1995-10-08         38.0  \n",
      "158        Florida    03-01-1985   1969-10-14         64.0  \n",
      "159             CA     2017-01-31  1985-10-10         48.0  \n",
      "\n",
      "[160 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "#def age_add_10(x):\n",
    "#    if isinstance(x, (int, float)):\n",
    "#        return x + 10\n",
    "#    return x\n",
    "\n",
    "#df['Age plus 10'] = df['Age'].apply(age_add_10)\n",
    "#print(df)\n",
    "\n",
    "df['Age'] = df['Age'].apply(lambda x: float(x) + 10)\n",
    "print(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Write a line of code to apply a function that converts all names in the ‘Name’ column to uppercase.\n",
    "\n",
    "Note: The .apply() function can be used with string methods to perform operations on each string in a column, e.g. .upper()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x,(\u001b[38;5;28mstr\u001b[39m)):\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mupper()\n\u001b[1;32m----> 5\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[43mx\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "def upper_case(x):\n",
    "    if isinstance(x,(str)):\n",
    "        return x.upper()\n",
    "\n",
    "df['Name'] = df['Name'].apply(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Write a line of code to concatenate df and df2 along rows.\n",
    "\n",
    "```\n",
    "# Creating a second DataFrame\n",
    "data2 = {\n",
    "    'Name': ['John', 'Jane'],\n",
    "    'Age': [30, 25],\n",
    "    'City': ['New York', 'Los Angeles'],\n",
    "    'Salary': [70000, 80000],\n",
    "    'Gender': ['Male', 'Female'],\n",
    "    'column1': ['Doe', 'Doe'],\n",
    "    'State': ['NY', 'CA'],\n",
    "    'Start Date': ['2010-01-01', '2012-07-01'],\n",
    "    'DateOfBirth': ['1990-01-01', '1997-07-01']\n",
    "}\n",
    "df2 = pd.DataFrame(data2)\n",
    "```\n",
    "\n",
    "Note: The pd.concat() function is useful for concatenating two or more pandas objects along a particular axis. By default, it concatenates along rows (i.e., axis=0). This is often used when you want to append rows from one DataFrame to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Gender</th>\n",
       "      <th>column1</th>\n",
       "      <th>State</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>DateOfBirth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joseph</td>\n",
       "      <td>44.0</td>\n",
       "      <td>naperville</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>other</td>\n",
       "      <td>Holmes</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>2014-10-16</td>\n",
       "      <td>1979-10-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joshua</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aurora</td>\n",
       "      <td>154000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Young</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>2002-05-06</td>\n",
       "      <td>2023-05-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yvonne</td>\n",
       "      <td>49.0</td>\n",
       "      <td>None</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Martin</td>\n",
       "      <td>None</td>\n",
       "      <td>1994</td>\n",
       "      <td>1974-10-13 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nicole</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Rochester</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>Zuniga</td>\n",
       "      <td>New York</td>\n",
       "      <td>1999-05-21</td>\n",
       "      <td>1996-10-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adam</td>\n",
       "      <td>47.0</td>\n",
       "      <td>fort wayne</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Ramirez</td>\n",
       "      <td>IN</td>\n",
       "      <td>2021-04-10</td>\n",
       "      <td>1976-10-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name   Age        City    Salary  Gender  column1     State  Start Date  \\\n",
       "0  joseph  44.0  naperville  105000.0   other   Holmes  Illinois  2014-10-16   \n",
       "1  Joshua   NaN      aurora  154000.0    None    Young  Illinois  2002-05-06   \n",
       "2  yvonne  49.0        None   35000.0  Female   Martin      None        1994   \n",
       "3  nicole  27.0   Rochester   54000.0   Other   Zuniga  New York  1999-05-21   \n",
       "4    Adam  47.0  fort wayne   72000.0    None  Ramirez        IN  2021-04-10   \n",
       "\n",
       "           DateOfBirth  \n",
       "0           1979-10-12  \n",
       "1           2023-05-21  \n",
       "2  1974-10-13 00:00:00  \n",
       "3           1996-10-07  \n",
       "4           1976-10-12  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the dataframe 1\n",
    "data = {\n",
    "    'Name': ['joseph', 'Joshua', 'yvonne', 'nicole', 'Adam'],\n",
    "    'Age': [44.0, None, 49.0, 27.0, 47.0],\n",
    "    'City': ['naperville', 'aurora', None, 'Rochester', 'fort wayne'],\n",
    "    'Salary': [105000.0, 154000.0, 35000.0, 54000.0, 72000.0],\n",
    "    'Gender': ['other', None, 'Female', 'Other', None],\n",
    "    'column1': ['Holmes', 'Young', 'Martin', 'Zuniga', 'Ramirez'],\n",
    "    'State': ['Illinois', 'Illinois', None, 'New York', 'IN'],\n",
    "    'Start Date': ['2014-10-16', '2002-05-06', '1994', '1999-05-21', '2021-04-10'],\n",
    "    'DateOfBirth': ['1979-10-12', '2023-05-21', '1974-10-13 00:00:00', '1996-10-07', '1976-10-12']\n",
    "}\n",
    "\n",
    "# Convert the dictionary into a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Gender</th>\n",
       "      <th>column1</th>\n",
       "      <th>State</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>DateOfBirth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "      <td>30</td>\n",
       "      <td>New York</td>\n",
       "      <td>70000</td>\n",
       "      <td>Male</td>\n",
       "      <td>Doe</td>\n",
       "      <td>NY</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>1990-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jane</td>\n",
       "      <td>25</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>80000</td>\n",
       "      <td>Female</td>\n",
       "      <td>Doe</td>\n",
       "      <td>CA</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>1997-07-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Name  Age         City  Salary  Gender column1 State  Start Date  \\\n",
       "0  John   30     New York   70000    Male     Doe    NY  2010-01-01   \n",
       "1  Jane   25  Los Angeles   80000  Female     Doe    CA  2012-07-01   \n",
       "\n",
       "  DateOfBirth  \n",
       "0  1990-01-01  \n",
       "1  1997-07-01  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a second DataFrame\n",
    "data2 = {\n",
    "    'Name': ['John', 'Jane'],\n",
    "    'Age': [30, 25],\n",
    "    'City': ['New York', 'Los Angeles'],\n",
    "    'Salary': [70000, 80000],\n",
    "    'Gender': ['Male', 'Female'],\n",
    "    'column1': ['Doe', 'Doe'],\n",
    "    'State': ['NY', 'CA'],\n",
    "    'Start Date': ['2010-01-01', '2012-07-01'],\n",
    "    'DateOfBirth': ['1990-01-01', '1997-07-01']\n",
    "}\n",
    "df2 = pd.DataFrame(data2)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name   Age         City    Salary  Gender  column1     State  Start Date  \\\n",
      "0  joseph  44.0   naperville  105000.0   other   Holmes  Illinois  2014-10-16   \n",
      "1  Joshua   NaN       aurora  154000.0    None    Young  Illinois  2002-05-06   \n",
      "2  yvonne  49.0         None   35000.0  Female   Martin      None        1994   \n",
      "3  nicole  27.0    Rochester   54000.0   Other   Zuniga  New York  1999-05-21   \n",
      "4    Adam  47.0   fort wayne   72000.0    None  Ramirez        IN  2021-04-10   \n",
      "0    John  30.0     New York   70000.0    Male      Doe        NY  2010-01-01   \n",
      "1    Jane  25.0  Los Angeles   80000.0  Female      Doe        CA  2012-07-01   \n",
      "\n",
      "           DateOfBirth  \n",
      "0           1979-10-12  \n",
      "1           2023-05-21  \n",
      "2  1974-10-13 00:00:00  \n",
      "3           1996-10-07  \n",
      "4           1976-10-12  \n",
      "0           1990-01-01  \n",
      "1           1997-07-01  \n"
     ]
    }
   ],
   "source": [
    "result = pd.concat([df, df2], axis=0)\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Write a line of code to concatenate df and df2 along columns.\n",
    "\n",
    "Note: By specifying axis=1 in the pd.concat() function, you can concatenate DataFrames along columns instead of rows. This is useful when you want to add new columns to a DataFrame from another DataFrame with the same index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name   Age        City    Salary  Gender  column1     State  Start Date  \\\n",
      "0  joseph  44.0  naperville  105000.0   other   Holmes  Illinois  2014-10-16   \n",
      "1  Joshua   NaN      aurora  154000.0    None    Young  Illinois  2002-05-06   \n",
      "2  yvonne  49.0        None   35000.0  Female   Martin      None        1994   \n",
      "3  nicole  27.0   Rochester   54000.0   Other   Zuniga  New York  1999-05-21   \n",
      "4    Adam  47.0  fort wayne   72000.0    None  Ramirez        IN  2021-04-10   \n",
      "\n",
      "           DateOfBirth  Name   Age         City   Salary  Gender column1  \\\n",
      "0           1979-10-12  John  30.0     New York  70000.0    Male     Doe   \n",
      "1           2023-05-21  Jane  25.0  Los Angeles  80000.0  Female     Doe   \n",
      "2  1974-10-13 00:00:00   NaN   NaN          NaN      NaN     NaN     NaN   \n",
      "3           1996-10-07   NaN   NaN          NaN      NaN     NaN     NaN   \n",
      "4           1976-10-12   NaN   NaN          NaN      NaN     NaN     NaN   \n",
      "\n",
      "  State  Start Date DateOfBirth  \n",
      "0    NY  2010-01-01  1990-01-01  \n",
      "1    CA  2012-07-01  1997-07-01  \n",
      "2   NaN         NaN         NaN  \n",
      "3   NaN         NaN         NaN  \n",
      "4   NaN         NaN         NaN  \n"
     ]
    }
   ],
   "source": [
    "result = pd.concat([df, df2], axis=1)\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Write a line of code to concatenate df and df2, and ignore the original index.\n",
    "\n",
    "Note: The ignore_index=True parameter in the pd.concat() function is useful when you want to ignore the original index and reset it in the resulting DataFrame. This is often used when the index does not contain any meaningful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name   Age         City    Salary  Gender  column1     State  Start Date  \\\n",
      "0  joseph  44.0   naperville  105000.0   other   Holmes  Illinois  2014-10-16   \n",
      "1  Joshua   NaN       aurora  154000.0    None    Young  Illinois  2002-05-06   \n",
      "2  yvonne  49.0         None   35000.0  Female   Martin      None        1994   \n",
      "3  nicole  27.0    Rochester   54000.0   Other   Zuniga  New York  1999-05-21   \n",
      "4    Adam  47.0   fort wayne   72000.0    None  Ramirez        IN  2021-04-10   \n",
      "5    John  30.0     New York   70000.0    Male      Doe        NY  2010-01-01   \n",
      "6    Jane  25.0  Los Angeles   80000.0  Female      Doe        CA  2012-07-01   \n",
      "\n",
      "           DateOfBirth  \n",
      "0           1979-10-12  \n",
      "1           2023-05-21  \n",
      "2  1974-10-13 00:00:00  \n",
      "3           1996-10-07  \n",
      "4           1976-10-12  \n",
      "5           1990-01-01  \n",
      "6           1997-07-01  \n"
     ]
    }
   ],
   "source": [
    "result = pd.concat([df, df2], ignore_index=True)\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5 (Homework): Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Identifier</th>\n",
       "      <th>Role</th>\n",
       "      <th>Years_of_Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>Role11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>Role12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>Role13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>Role14</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>Role15</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Identifier    Role  Years_of_Experience\n",
       "0          11  Role11                    1\n",
       "1          12  Role12                    2\n",
       "2          13  Role13                    3\n",
       "3          14  Role14                    4\n",
       "4          15  Role15                    5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create dataframes function\n",
    "\n",
    "def create_joins_df():\n",
    "    # Creating DataFrame df1\n",
    "    data1 = {\n",
    "        'ID': list(range(1, 21)),\n",
    "        'Name': ['Employee'+str(i) for i in range(1, 21)],\n",
    "        'Department': ['Sales', 'Marketing', 'HR', 'Sales', 'IT', 'Marketing', 'HR', 'IT', 'Sales', 'Marketing',\n",
    "                    'HR', 'IT', 'Sales', 'Marketing', 'HR', 'IT', 'Sales', 'Marketing', 'HR', 'IT'],\n",
    "        'Start_Date': pd.date_range(start='01-01-2020', periods=20),\n",
    "        'Salary': [i*1000 for i in range(50, 70)]\n",
    "    }\n",
    "    df1 = pd.DataFrame(data1)\n",
    "\n",
    "    # Creating DataFrame df2\n",
    "    data2 = {\n",
    "        'Identifier': list(range(11, 31)),\n",
    "        'Role': ['Role'+str(i) for i in range(11, 31)],\n",
    "        'Years_of_Experience': [i for i in range(1, 21)]\n",
    "    }\n",
    "    df2 = pd.DataFrame(data2)\n",
    "\n",
    "    return df1, df2\n",
    "\n",
    "# Run DataFrame creation function\n",
    "df1, df2 = create_joins_df()\n",
    "df1.head(5)\n",
    "df2.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Write a line of code to perform an inner join of df1 and df2 on the ‘ID’ column.\n",
    "\n",
    "Note: The merge() function with how='inner' is useful for combining two DataFrames based on a common column, and only keeping rows that have matching values in both DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID        Name Department Start_Date  Salary  Identifier    Role  \\\n",
      "0  11  Employee11         HR 2020-01-11   60000          11  Role11   \n",
      "1  12  Employee12         IT 2020-01-12   61000          12  Role12   \n",
      "2  13  Employee13      Sales 2020-01-13   62000          13  Role13   \n",
      "3  14  Employee14  Marketing 2020-01-14   63000          14  Role14   \n",
      "4  15  Employee15         HR 2020-01-15   64000          15  Role15   \n",
      "5  16  Employee16         IT 2020-01-16   65000          16  Role16   \n",
      "6  17  Employee17      Sales 2020-01-17   66000          17  Role17   \n",
      "7  18  Employee18  Marketing 2020-01-18   67000          18  Role18   \n",
      "8  19  Employee19         HR 2020-01-19   68000          19  Role19   \n",
      "9  20  Employee20         IT 2020-01-20   69000          20  Role20   \n",
      "\n",
      "   Years_of_Experience  \n",
      "0                    1  \n",
      "1                    2  \n",
      "2                    3  \n",
      "3                    4  \n",
      "4                    5  \n",
      "5                    6  \n",
      "6                    7  \n",
      "7                    8  \n",
      "8                    9  \n",
      "9                   10  \n"
     ]
    }
   ],
   "source": [
    "# Run DataFrame creation function\n",
    "df1, df2 = create_joins_df()\n",
    "\n",
    "result =pd.merge(df1, df2, left_on='ID', right_on='Identifier', how='inner')\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Write a line of code to perform an outer join of df1 and df2 on the ‘ID’ column.\n",
    "\n",
    "Note: The merge() function with how='outer' is useful for combining two DataFrames based on a common column, and keeping all rows from both DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID        Name Department Start_Date   Salary  Identifier    Role  \\\n",
      "0    1.0   Employee1      Sales 2020-01-01  50000.0         NaN     NaN   \n",
      "1    2.0   Employee2  Marketing 2020-01-02  51000.0         NaN     NaN   \n",
      "2    3.0   Employee3         HR 2020-01-03  52000.0         NaN     NaN   \n",
      "3    4.0   Employee4      Sales 2020-01-04  53000.0         NaN     NaN   \n",
      "4    5.0   Employee5         IT 2020-01-05  54000.0         NaN     NaN   \n",
      "5    6.0   Employee6  Marketing 2020-01-06  55000.0         NaN     NaN   \n",
      "6    7.0   Employee7         HR 2020-01-07  56000.0         NaN     NaN   \n",
      "7    8.0   Employee8         IT 2020-01-08  57000.0         NaN     NaN   \n",
      "8    9.0   Employee9      Sales 2020-01-09  58000.0         NaN     NaN   \n",
      "9   10.0  Employee10  Marketing 2020-01-10  59000.0         NaN     NaN   \n",
      "10  11.0  Employee11         HR 2020-01-11  60000.0        11.0  Role11   \n",
      "11  12.0  Employee12         IT 2020-01-12  61000.0        12.0  Role12   \n",
      "12  13.0  Employee13      Sales 2020-01-13  62000.0        13.0  Role13   \n",
      "13  14.0  Employee14  Marketing 2020-01-14  63000.0        14.0  Role14   \n",
      "14  15.0  Employee15         HR 2020-01-15  64000.0        15.0  Role15   \n",
      "15  16.0  Employee16         IT 2020-01-16  65000.0        16.0  Role16   \n",
      "16  17.0  Employee17      Sales 2020-01-17  66000.0        17.0  Role17   \n",
      "17  18.0  Employee18  Marketing 2020-01-18  67000.0        18.0  Role18   \n",
      "18  19.0  Employee19         HR 2020-01-19  68000.0        19.0  Role19   \n",
      "19  20.0  Employee20         IT 2020-01-20  69000.0        20.0  Role20   \n",
      "20   NaN         NaN        NaN        NaT      NaN        21.0  Role21   \n",
      "21   NaN         NaN        NaN        NaT      NaN        22.0  Role22   \n",
      "22   NaN         NaN        NaN        NaT      NaN        23.0  Role23   \n",
      "23   NaN         NaN        NaN        NaT      NaN        24.0  Role24   \n",
      "24   NaN         NaN        NaN        NaT      NaN        25.0  Role25   \n",
      "25   NaN         NaN        NaN        NaT      NaN        26.0  Role26   \n",
      "26   NaN         NaN        NaN        NaT      NaN        27.0  Role27   \n",
      "27   NaN         NaN        NaN        NaT      NaN        28.0  Role28   \n",
      "28   NaN         NaN        NaN        NaT      NaN        29.0  Role29   \n",
      "29   NaN         NaN        NaN        NaT      NaN        30.0  Role30   \n",
      "\n",
      "    Years_of_Experience  \n",
      "0                   NaN  \n",
      "1                   NaN  \n",
      "2                   NaN  \n",
      "3                   NaN  \n",
      "4                   NaN  \n",
      "5                   NaN  \n",
      "6                   NaN  \n",
      "7                   NaN  \n",
      "8                   NaN  \n",
      "9                   NaN  \n",
      "10                  1.0  \n",
      "11                  2.0  \n",
      "12                  3.0  \n",
      "13                  4.0  \n",
      "14                  5.0  \n",
      "15                  6.0  \n",
      "16                  7.0  \n",
      "17                  8.0  \n",
      "18                  9.0  \n",
      "19                 10.0  \n",
      "20                 11.0  \n",
      "21                 12.0  \n",
      "22                 13.0  \n",
      "23                 14.0  \n",
      "24                 15.0  \n",
      "25                 16.0  \n",
      "26                 17.0  \n",
      "27                 18.0  \n",
      "28                 19.0  \n",
      "29                 20.0  \n"
     ]
    }
   ],
   "source": [
    "# Run DataFrame creation function\n",
    "df1, df2 = create_joins_df()\n",
    "result = pd.merge(df1, df2, left_on='ID', right_on='Identifier', how='outer')\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Write a line of code to join df1 and df2 on different column names (‘ID’ in df1 and ‘Identifier’ in df2).\n",
    "\n",
    "Note: The merge() function with left_on and right_on parameters is useful for combining two DataFrames based on different column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID        Name Department Start_Date   Salary  Identifier    Role  \\\n",
      "0    1.0   Employee1      Sales 2020-01-01  50000.0         NaN     NaN   \n",
      "1    2.0   Employee2  Marketing 2020-01-02  51000.0         NaN     NaN   \n",
      "2    3.0   Employee3         HR 2020-01-03  52000.0         NaN     NaN   \n",
      "3    4.0   Employee4      Sales 2020-01-04  53000.0         NaN     NaN   \n",
      "4    5.0   Employee5         IT 2020-01-05  54000.0         NaN     NaN   \n",
      "5    6.0   Employee6  Marketing 2020-01-06  55000.0         NaN     NaN   \n",
      "6    7.0   Employee7         HR 2020-01-07  56000.0         NaN     NaN   \n",
      "7    8.0   Employee8         IT 2020-01-08  57000.0         NaN     NaN   \n",
      "8    9.0   Employee9      Sales 2020-01-09  58000.0         NaN     NaN   \n",
      "9   10.0  Employee10  Marketing 2020-01-10  59000.0         NaN     NaN   \n",
      "10  11.0  Employee11         HR 2020-01-11  60000.0        11.0  Role11   \n",
      "11  12.0  Employee12         IT 2020-01-12  61000.0        12.0  Role12   \n",
      "12  13.0  Employee13      Sales 2020-01-13  62000.0        13.0  Role13   \n",
      "13  14.0  Employee14  Marketing 2020-01-14  63000.0        14.0  Role14   \n",
      "14  15.0  Employee15         HR 2020-01-15  64000.0        15.0  Role15   \n",
      "15  16.0  Employee16         IT 2020-01-16  65000.0        16.0  Role16   \n",
      "16  17.0  Employee17      Sales 2020-01-17  66000.0        17.0  Role17   \n",
      "17  18.0  Employee18  Marketing 2020-01-18  67000.0        18.0  Role18   \n",
      "18  19.0  Employee19         HR 2020-01-19  68000.0        19.0  Role19   \n",
      "19  20.0  Employee20         IT 2020-01-20  69000.0        20.0  Role20   \n",
      "20   NaN         NaN        NaN        NaT      NaN        21.0  Role21   \n",
      "21   NaN         NaN        NaN        NaT      NaN        22.0  Role22   \n",
      "22   NaN         NaN        NaN        NaT      NaN        23.0  Role23   \n",
      "23   NaN         NaN        NaN        NaT      NaN        24.0  Role24   \n",
      "24   NaN         NaN        NaN        NaT      NaN        25.0  Role25   \n",
      "25   NaN         NaN        NaN        NaT      NaN        26.0  Role26   \n",
      "26   NaN         NaN        NaN        NaT      NaN        27.0  Role27   \n",
      "27   NaN         NaN        NaN        NaT      NaN        28.0  Role28   \n",
      "28   NaN         NaN        NaN        NaT      NaN        29.0  Role29   \n",
      "29   NaN         NaN        NaN        NaT      NaN        30.0  Role30   \n",
      "\n",
      "    Years_of_Experience  \n",
      "0                   NaN  \n",
      "1                   NaN  \n",
      "2                   NaN  \n",
      "3                   NaN  \n",
      "4                   NaN  \n",
      "5                   NaN  \n",
      "6                   NaN  \n",
      "7                   NaN  \n",
      "8                   NaN  \n",
      "9                   NaN  \n",
      "10                  1.0  \n",
      "11                  2.0  \n",
      "12                  3.0  \n",
      "13                  4.0  \n",
      "14                  5.0  \n",
      "15                  6.0  \n",
      "16                  7.0  \n",
      "17                  8.0  \n",
      "18                  9.0  \n",
      "19                 10.0  \n",
      "20                 11.0  \n",
      "21                 12.0  \n",
      "22                 13.0  \n",
      "23                 14.0  \n",
      "24                 15.0  \n",
      "25                 16.0  \n",
      "26                 17.0  \n",
      "27                 18.0  \n",
      "28                 19.0  \n",
      "29                 20.0  \n"
     ]
    }
   ],
   "source": [
    "# Run DataFrame creation function\n",
    "df1, df2 = create_joins_df()\n",
    "df1, df2 = create_joins_df()\n",
    "result = pd.merge(df1, df2, left_on='ID', right_on='Identifier', how='outer')\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Write a line of code to join df1 and df2 on their indices.\n",
    "\n",
    "Note: The join() function is useful for combining two DataFrames based on their indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ID        Name Department Start_Date  Salary  Identifier    Role  \\\n",
      "0    1   Employee1      Sales 2020-01-01   50000          11  Role11   \n",
      "1    2   Employee2  Marketing 2020-01-02   51000          12  Role12   \n",
      "2    3   Employee3         HR 2020-01-03   52000          13  Role13   \n",
      "3    4   Employee4      Sales 2020-01-04   53000          14  Role14   \n",
      "4    5   Employee5         IT 2020-01-05   54000          15  Role15   \n",
      "5    6   Employee6  Marketing 2020-01-06   55000          16  Role16   \n",
      "6    7   Employee7         HR 2020-01-07   56000          17  Role17   \n",
      "7    8   Employee8         IT 2020-01-08   57000          18  Role18   \n",
      "8    9   Employee9      Sales 2020-01-09   58000          19  Role19   \n",
      "9   10  Employee10  Marketing 2020-01-10   59000          20  Role20   \n",
      "10  11  Employee11         HR 2020-01-11   60000          21  Role21   \n",
      "11  12  Employee12         IT 2020-01-12   61000          22  Role22   \n",
      "12  13  Employee13      Sales 2020-01-13   62000          23  Role23   \n",
      "13  14  Employee14  Marketing 2020-01-14   63000          24  Role24   \n",
      "14  15  Employee15         HR 2020-01-15   64000          25  Role25   \n",
      "15  16  Employee16         IT 2020-01-16   65000          26  Role26   \n",
      "16  17  Employee17      Sales 2020-01-17   66000          27  Role27   \n",
      "17  18  Employee18  Marketing 2020-01-18   67000          28  Role28   \n",
      "18  19  Employee19         HR 2020-01-19   68000          29  Role29   \n",
      "19  20  Employee20         IT 2020-01-20   69000          30  Role30   \n",
      "\n",
      "    Years_of_Experience  \n",
      "0                     1  \n",
      "1                     2  \n",
      "2                     3  \n",
      "3                     4  \n",
      "4                     5  \n",
      "5                     6  \n",
      "6                     7  \n",
      "7                     8  \n",
      "8                     9  \n",
      "9                    10  \n",
      "10                   11  \n",
      "11                   12  \n",
      "12                   13  \n",
      "13                   14  \n",
      "14                   15  \n",
      "15                   16  \n",
      "16                   17  \n",
      "17                   18  \n",
      "18                   19  \n",
      "19                   20  \n"
     ]
    }
   ],
   "source": [
    "# Run DataFrame creation function\n",
    "df1, df2 = create_joins_df()\n",
    "\n",
    "#result = pd.join(df1,df2, how='inner', lsuffix='_df1', rsuffix='_df2')\n",
    "df3 = df1.join(df2, how='inner', lsuffix='_df1', rsuffix='_df2')\n",
    "print(df3)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Write a line of code to perform a left join of df1 and df2 on the ‘ID’ column.\n",
    "\n",
    "Note: The merge() function with how='left' is useful for combining two DataFrames based on a common column, and keeping all rows from the left DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ID        Name Department Start_Date  Salary  Identifier    Role  \\\n",
      "0    1   Employee1      Sales 2020-01-01   50000         NaN     NaN   \n",
      "1    2   Employee2  Marketing 2020-01-02   51000         NaN     NaN   \n",
      "2    3   Employee3         HR 2020-01-03   52000         NaN     NaN   \n",
      "3    4   Employee4      Sales 2020-01-04   53000         NaN     NaN   \n",
      "4    5   Employee5         IT 2020-01-05   54000         NaN     NaN   \n",
      "5    6   Employee6  Marketing 2020-01-06   55000         NaN     NaN   \n",
      "6    7   Employee7         HR 2020-01-07   56000         NaN     NaN   \n",
      "7    8   Employee8         IT 2020-01-08   57000         NaN     NaN   \n",
      "8    9   Employee9      Sales 2020-01-09   58000         NaN     NaN   \n",
      "9   10  Employee10  Marketing 2020-01-10   59000         NaN     NaN   \n",
      "10  11  Employee11         HR 2020-01-11   60000        11.0  Role11   \n",
      "11  12  Employee12         IT 2020-01-12   61000        12.0  Role12   \n",
      "12  13  Employee13      Sales 2020-01-13   62000        13.0  Role13   \n",
      "13  14  Employee14  Marketing 2020-01-14   63000        14.0  Role14   \n",
      "14  15  Employee15         HR 2020-01-15   64000        15.0  Role15   \n",
      "15  16  Employee16         IT 2020-01-16   65000        16.0  Role16   \n",
      "16  17  Employee17      Sales 2020-01-17   66000        17.0  Role17   \n",
      "17  18  Employee18  Marketing 2020-01-18   67000        18.0  Role18   \n",
      "18  19  Employee19         HR 2020-01-19   68000        19.0  Role19   \n",
      "19  20  Employee20         IT 2020-01-20   69000        20.0  Role20   \n",
      "\n",
      "    Years_of_Experience  \n",
      "0                   NaN  \n",
      "1                   NaN  \n",
      "2                   NaN  \n",
      "3                   NaN  \n",
      "4                   NaN  \n",
      "5                   NaN  \n",
      "6                   NaN  \n",
      "7                   NaN  \n",
      "8                   NaN  \n",
      "9                   NaN  \n",
      "10                  1.0  \n",
      "11                  2.0  \n",
      "12                  3.0  \n",
      "13                  4.0  \n",
      "14                  5.0  \n",
      "15                  6.0  \n",
      "16                  7.0  \n",
      "17                  8.0  \n",
      "18                  9.0  \n",
      "19                 10.0  \n"
     ]
    }
   ],
   "source": [
    "# Run DataFrame creation function\n",
    "df1, df2 = create_joins_df()\n",
    "\n",
    "result = pd.merge(df1, df2, left_on='ID', right_on='Identifier', how='left')\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Write a line of code to perform a right join of df1 and df2 on the ‘ID’ column.\n",
    "\n",
    "Note: The merge() function with how='right' is useful for combining two DataFrames based on a common column, and keeping all rows from the right DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID        Name Department Start_Date   Salary  Identifier    Role  \\\n",
      "0   11.0  Employee11         HR 2020-01-11  60000.0          11  Role11   \n",
      "1   12.0  Employee12         IT 2020-01-12  61000.0          12  Role12   \n",
      "2   13.0  Employee13      Sales 2020-01-13  62000.0          13  Role13   \n",
      "3   14.0  Employee14  Marketing 2020-01-14  63000.0          14  Role14   \n",
      "4   15.0  Employee15         HR 2020-01-15  64000.0          15  Role15   \n",
      "5   16.0  Employee16         IT 2020-01-16  65000.0          16  Role16   \n",
      "6   17.0  Employee17      Sales 2020-01-17  66000.0          17  Role17   \n",
      "7   18.0  Employee18  Marketing 2020-01-18  67000.0          18  Role18   \n",
      "8   19.0  Employee19         HR 2020-01-19  68000.0          19  Role19   \n",
      "9   20.0  Employee20         IT 2020-01-20  69000.0          20  Role20   \n",
      "10   NaN         NaN        NaN        NaT      NaN          21  Role21   \n",
      "11   NaN         NaN        NaN        NaT      NaN          22  Role22   \n",
      "12   NaN         NaN        NaN        NaT      NaN          23  Role23   \n",
      "13   NaN         NaN        NaN        NaT      NaN          24  Role24   \n",
      "14   NaN         NaN        NaN        NaT      NaN          25  Role25   \n",
      "15   NaN         NaN        NaN        NaT      NaN          26  Role26   \n",
      "16   NaN         NaN        NaN        NaT      NaN          27  Role27   \n",
      "17   NaN         NaN        NaN        NaT      NaN          28  Role28   \n",
      "18   NaN         NaN        NaN        NaT      NaN          29  Role29   \n",
      "19   NaN         NaN        NaN        NaT      NaN          30  Role30   \n",
      "\n",
      "    Years_of_Experience  \n",
      "0                     1  \n",
      "1                     2  \n",
      "2                     3  \n",
      "3                     4  \n",
      "4                     5  \n",
      "5                     6  \n",
      "6                     7  \n",
      "7                     8  \n",
      "8                     9  \n",
      "9                    10  \n",
      "10                   11  \n",
      "11                   12  \n",
      "12                   13  \n",
      "13                   14  \n",
      "14                   15  \n",
      "15                   16  \n",
      "16                   17  \n",
      "17                   18  \n",
      "18                   19  \n",
      "19                   20  \n"
     ]
    }
   ],
   "source": [
    "# Run DataFrame creation function\n",
    "df1, df2 = create_joins_df()\n",
    "\n",
    "result = pd.merge(df1, df2, left_on='ID', right_on='Identifier', how='right')\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. Write a line of code to join df1 and df2 on the ‘ID’ column, where ‘ID’ is the index in df1 and a regular column in df2.\n",
    "\n",
    "Note: The combination of the .set_index() function and the .join() function is useful when you want to join two DataFrames based on an index in one DataFrame and a regular column in another DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Name</th>\n",
       "      <th>Department</th>\n",
       "      <th>Start_Date</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Role</th>\n",
       "      <th>Years_of_Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>Employee11</td>\n",
       "      <td>HR</td>\n",
       "      <td>2020-01-11</td>\n",
       "      <td>60000</td>\n",
       "      <td>Role11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>Employee12</td>\n",
       "      <td>IT</td>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>61000</td>\n",
       "      <td>Role12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>Employee13</td>\n",
       "      <td>Sales</td>\n",
       "      <td>2020-01-13</td>\n",
       "      <td>62000</td>\n",
       "      <td>Role13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>Employee14</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>63000</td>\n",
       "      <td>Role14</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>Employee15</td>\n",
       "      <td>HR</td>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>64000</td>\n",
       "      <td>Role15</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16</td>\n",
       "      <td>Employee16</td>\n",
       "      <td>IT</td>\n",
       "      <td>2020-01-16</td>\n",
       "      <td>65000</td>\n",
       "      <td>Role16</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17</td>\n",
       "      <td>Employee17</td>\n",
       "      <td>Sales</td>\n",
       "      <td>2020-01-17</td>\n",
       "      <td>66000</td>\n",
       "      <td>Role17</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18</td>\n",
       "      <td>Employee18</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>2020-01-18</td>\n",
       "      <td>67000</td>\n",
       "      <td>Role18</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19</td>\n",
       "      <td>Employee19</td>\n",
       "      <td>HR</td>\n",
       "      <td>2020-01-19</td>\n",
       "      <td>68000</td>\n",
       "      <td>Role19</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20</td>\n",
       "      <td>Employee20</td>\n",
       "      <td>IT</td>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>69000</td>\n",
       "      <td>Role20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index        Name Department Start_Date  Salary    Role  \\\n",
       "0     11  Employee11         HR 2020-01-11   60000  Role11   \n",
       "1     12  Employee12         IT 2020-01-12   61000  Role12   \n",
       "2     13  Employee13      Sales 2020-01-13   62000  Role13   \n",
       "3     14  Employee14  Marketing 2020-01-14   63000  Role14   \n",
       "4     15  Employee15         HR 2020-01-15   64000  Role15   \n",
       "5     16  Employee16         IT 2020-01-16   65000  Role16   \n",
       "6     17  Employee17      Sales 2020-01-17   66000  Role17   \n",
       "7     18  Employee18  Marketing 2020-01-18   67000  Role18   \n",
       "8     19  Employee19         HR 2020-01-19   68000  Role19   \n",
       "9     20  Employee20         IT 2020-01-20   69000  Role20   \n",
       "\n",
       "   Years_of_Experience  \n",
       "0                    1  \n",
       "1                    2  \n",
       "2                    3  \n",
       "3                    4  \n",
       "4                    5  \n",
       "5                    6  \n",
       "6                    7  \n",
       "7                    8  \n",
       "8                    9  \n",
       "9                   10  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run DataFrame creation function\n",
    "df1, df2 = create_joins_df()\n",
    "\n",
    "df3 = df1.set_index('ID').join(df2.set_index('Identifier'), how='inner').reset_index()\n",
    "df3\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. Write a line of code to join df1 and df2, where ‘ID’ is a regular column in both DataFrames, but treat it as an index only for the purpose of joining.\n",
    "\n",
    "Note: The combination of the .set_index(), .join(), and .reset_index() functions is useful when you want to join two DataFrames based on a common column, but don’t want this column to be the index in your resulting DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Name</th>\n",
       "      <th>Department</th>\n",
       "      <th>Start_Date</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Role</th>\n",
       "      <th>Years_of_Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>Employee11</td>\n",
       "      <td>HR</td>\n",
       "      <td>2020-01-11</td>\n",
       "      <td>60000</td>\n",
       "      <td>Role11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>Employee12</td>\n",
       "      <td>IT</td>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>61000</td>\n",
       "      <td>Role12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>Employee13</td>\n",
       "      <td>Sales</td>\n",
       "      <td>2020-01-13</td>\n",
       "      <td>62000</td>\n",
       "      <td>Role13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>Employee14</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>63000</td>\n",
       "      <td>Role14</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>Employee15</td>\n",
       "      <td>HR</td>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>64000</td>\n",
       "      <td>Role15</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16</td>\n",
       "      <td>Employee16</td>\n",
       "      <td>IT</td>\n",
       "      <td>2020-01-16</td>\n",
       "      <td>65000</td>\n",
       "      <td>Role16</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17</td>\n",
       "      <td>Employee17</td>\n",
       "      <td>Sales</td>\n",
       "      <td>2020-01-17</td>\n",
       "      <td>66000</td>\n",
       "      <td>Role17</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18</td>\n",
       "      <td>Employee18</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>2020-01-18</td>\n",
       "      <td>67000</td>\n",
       "      <td>Role18</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19</td>\n",
       "      <td>Employee19</td>\n",
       "      <td>HR</td>\n",
       "      <td>2020-01-19</td>\n",
       "      <td>68000</td>\n",
       "      <td>Role19</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20</td>\n",
       "      <td>Employee20</td>\n",
       "      <td>IT</td>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>69000</td>\n",
       "      <td>Role20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index        Name Department Start_Date  Salary    Role  \\\n",
       "0     11  Employee11         HR 2020-01-11   60000  Role11   \n",
       "1     12  Employee12         IT 2020-01-12   61000  Role12   \n",
       "2     13  Employee13      Sales 2020-01-13   62000  Role13   \n",
       "3     14  Employee14  Marketing 2020-01-14   63000  Role14   \n",
       "4     15  Employee15         HR 2020-01-15   64000  Role15   \n",
       "5     16  Employee16         IT 2020-01-16   65000  Role16   \n",
       "6     17  Employee17      Sales 2020-01-17   66000  Role17   \n",
       "7     18  Employee18  Marketing 2020-01-18   67000  Role18   \n",
       "8     19  Employee19         HR 2020-01-19   68000  Role19   \n",
       "9     20  Employee20         IT 2020-01-20   69000  Role20   \n",
       "\n",
       "   Years_of_Experience  \n",
       "0                    1  \n",
       "1                    2  \n",
       "2                    3  \n",
       "3                    4  \n",
       "4                    5  \n",
       "5                    6  \n",
       "6                    7  \n",
       "7                    8  \n",
       "8                    9  \n",
       "9                   10  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run DataFrame creation function\n",
    "df1, df2 = create_joins_df()\n",
    "\n",
    "# Joining on 'ID' treated as index\n",
    "df3 = df1.set_index('ID').join(df2.set_index('Identifier'), how='inner').reset_index()\n",
    "df3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
